{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10265547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xcheng/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import xgboost as xgb\n",
    "import scipy as sp\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a29c3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original simulation data generation\n",
    "#input parameters: sample size, weight in the equation, max value of X (value range), tag to indicate the function between X and Y (0:Linear;1:Power;2:Trigonometric)\n",
    "#output results: original data of generated X, original data of the corresponding generated Y\n",
    "def generation(N,W,X_max,L):\n",
    "    X_data=[]\n",
    "    Y_data=[]\n",
    "    \n",
    "    #Linear, y=wx+b\n",
    "    if(L==0):\n",
    "        for i in range(N):\n",
    "            x=random.random()*X_max\n",
    "            b=random.random()*100\n",
    "            y=W*x+b\n",
    "        \n",
    "            X_data.append((x,L))\n",
    "            Y_data.append(y)\n",
    "    \n",
    "    #Power,y=wx^2+b\n",
    "    elif(L==1):\n",
    "        for i in range(N):\n",
    "            x=random.random()*X_max\n",
    "            b=random.random()*100\n",
    "            y=W*x*x+b\n",
    "        \n",
    "            X_data.append((x,L))\n",
    "            Y_data.append(y)\n",
    "\n",
    "    #Trigonometric,y=w(sin(x)+1)+b\n",
    "    elif(L==2):\n",
    "        for i in range(N):\n",
    "            x=random.random()*X_max\n",
    "            b=random.random()*100\n",
    "            y=W*(math.sin(x)+1)+b\n",
    "        \n",
    "            X_data.append((x,L))\n",
    "            Y_data.append(y)\n",
    "     \n",
    "    return X_data,Y_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aef0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resampling data according to the distribution density\n",
    "#input parameters: original data of X, original data of Y, the number of samples after resampling, intervals of X to present the distribution density, distribution density of Y\n",
    "#output results: resampled data of X, the corresponding resampled data of Y\n",
    "def resampling(data_x,data_y,N,density_x,density_y):\n",
    "    result_x=[]\n",
    "    result_y=[]\n",
    "    \n",
    "    #how many intervals\n",
    "    length=len(density_x)\n",
    "    \n",
    "    #length of the interval\n",
    "    x_start=density_x[0]\n",
    "    x_range=1.0*(density_x[1]-density_x[0])\n",
    "    \n",
    "    datapool=[]#samples Y in each interval according to their values\n",
    "    poolsize=[]#the number of samples in each interval\n",
    "    for i in range(length):\n",
    "        tmp=[]\n",
    "        if(i==length-1):\n",
    "            samplesize=N-np.sum(poolsize)\n",
    "        else:\n",
    "            samplesize=int(density_y[i]*N)\n",
    "        poolsize.append(samplesize)\n",
    "        datapool.append(tmp)\n",
    "        \n",
    "    for j in range(len(data_y)):\n",
    "        num=int((data_y[j]-x_start)/x_range)\n",
    "        \n",
    "        if(num>=length):\n",
    "            num=length-1\n",
    "        datapool[num].append(j)\n",
    "    \n",
    "    idpool=[]#ids of resampled samples in each interval\n",
    "    for i in range(length):\n",
    "        tmpsize=poolsize[i]\n",
    "        tmpid=np.random.choice(datapool[i],tmpsize,replace=True)\n",
    "        for j in tmpid:\n",
    "            idpool.append(j)\n",
    "            \n",
    "    #get the samples according to their ids\n",
    "    random.shuffle(idpool)\n",
    "    for i in idpool:\n",
    "        result_x.append(data_x[i])\n",
    "        result_y.append(data_y[i])\n",
    "    \n",
    "    return result_x,result_y\n",
    "\n",
    "#generate the distribution density and sample the data according to the distribution density\n",
    "#input parameters: the number of samples, original data of X, original data of Y, tag to indicate the distribution type (0: Normal distribution;1: Pareto distribution)\n",
    "#output results: resampled data of X, the corresponding resampled data of Y\n",
    "def densitysampling(N,input_x,input_y,D):\n",
    "    \n",
    "    #input_x_d=np.arange(start=np.min(input_y),stop=np.max(input_y),step=50)\n",
    "    input_x_d=np.arange(start=np.min(input_y),stop=np.max(input_y),step=(np.max(input_y)-np.min(input_y))/20.0)\n",
    "    \n",
    "    #Normal distribution\n",
    "    if(D==0):\n",
    "        #input_y_d=stats.norm.pdf(x=input_x_d,loc=(np.max(input_y)-np.min(input_y))/2.0+np.min(input_y),scale=200)\n",
    "        input_y_d=stats.norm.pdf(x=input_x_d,loc=(np.max(input_y)-np.min(input_y))/2.0+np.min(input_y),scale=(np.max(input_y)-np.min(input_y))/5.0)\n",
    "    #Pareto distribution\n",
    "    elif(D==1):\n",
    "        input_y_d=stats.pareto.pdf(x=input_x_d,loc=np.min(input_y),scale=1,b=0.05)    \n",
    "    \n",
    "    #Normalization\n",
    "    input_y_d=input_y_d/np.sum(input_y_d)\n",
    "\n",
    "    new_x,new_y=resampling(input_x,input_y,N,input_x_d,input_y_d)\n",
    "    \n",
    "    return new_x,new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9974d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the RMSE of forecasting on three data (entire data, data generated based on the first equation, data generated based on the second equation)\n",
    "def getresult(real_1,pred_1,real_2,pred_2):\n",
    "    totalreal=np.concatenate((np.array(real_1),np.array(real_2)),axis=0)\n",
    "    totalpred=np.concatenate((np.array(pred_1),np.array(pred_2)),axis=0)\n",
    "    \n",
    "    mse=metrics.mean_squared_error(totalreal,totalpred)\n",
    "    mse_1=metrics.mean_squared_error(real_1,pred_1)\n",
    "    mse_2=metrics.mean_squared_error(real_2,pred_2)\n",
    "    \n",
    "    return math.sqrt(mse),math.sqrt(mse_1),math.sqrt(mse_2)\n",
    "    \n",
    "#train XGBoost model and get the evaluation results\n",
    "#input parameter: the first eight parameters are the corresponding data, the last parameter indicates whether the predicted Y needs to be transformed back from its log transformation (1:transform;0:not) \n",
    "#output results: RMSE on entire data by global training, RMSE on data_1 by global training, RMSE on data_2 by global training, RMSE on entire data by local training,...\n",
    "def modeltraining(x_train_1,x_train_2,y_train_1,y_train_2,x_test_1,x_test_2,y_test_1,y_test_2,logtag):\n",
    "    totaltrain_x=np.concatenate((np.array(x_train_1),np.array(x_train_2)),axis=0)\n",
    "    totaltest_x=np.concatenate((np.array(x_test_1),np.array(x_test_2)),axis=0)\n",
    "    totaltrain_y=np.concatenate((np.array(y_train_1),np.array(y_train_2)),axis=0)\n",
    "    totaltest_y=np.concatenate((np.array(y_test_1),np.array(y_test_2)),axis=0)\n",
    "    \n",
    "    #global training\n",
    "    model_g=xgb.XGBRegressor(eval_metric='rmse')\n",
    "    model_g.fit(totaltrain_x,totaltrain_y)\n",
    "    g_pred_1=model_g.predict(x_test_1)\n",
    "    g_pred_2=model_g.predict(x_test_2)\n",
    "    \n",
    "    #transform back from log transformation\n",
    "    if(logtag==1):\n",
    "        g_pred_1=np.power(np.e,g_pred_1/200.0)\n",
    "        g_pred_2=np.power(np.e,g_pred_2/200.0)\n",
    "#         for i in range(len(g_pred_1)):\n",
    "#             g_pred_1[i]=math.pow(math.e,g_pred_1[i])\n",
    "#         for j in range(len(g_pred_2)):\n",
    "#             g_pred_2[j]=math.pow(math.e,g_pred_2[j])\n",
    "    \n",
    "    #local training\n",
    "    model_l1=xgb.XGBRegressor(eval_metric='rmse')\n",
    "    model_l1.fit(x_train_1,y_train_1)\n",
    "    l_pred_1=model_l1.predict(x_test_1)\n",
    "    \n",
    "    model_l2=xgb.XGBRegressor(eval_metric='rmse')\n",
    "    model_l2.fit(x_train_2,y_train_2)\n",
    "    l_pred_2=model_l2.predict(x_test_2)\n",
    "    \n",
    "    #transform back from log transformation\n",
    "    if(logtag==1):\n",
    "        l_pred_1=np.power(np.e,l_pred_1/200.0)\n",
    "        l_pred_2=np.power(np.e,l_pred_2/200.0)\n",
    "#         for i in range(len(l_pred_1)):\n",
    "#             l_pred_1[i]=math.pow(math.e,l_pred_1[i])\n",
    "#         for j in range(len(l_pred_2)):\n",
    "#             l_pred_2[j]=math.pow(math.e,l_pred_2[j])\n",
    "    \n",
    "    \n",
    "    g_rmse,g_rmse_1,g_rmse_2=getresult(y_test_1,g_pred_1,y_test_2,g_pred_2)\n",
    "    l_rmse,l_rmse_1,l_rmse_2=getresult(y_test_1,l_pred_1,y_test_2,l_pred_2)\n",
    "    \n",
    "    return g_rmse,g_rmse_1,g_rmse_2,l_rmse,l_rmse_1,l_rmse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac589682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visulization the value distribution of data\n",
    "def distribution(input_y):\n",
    "    #length=int(np.max(input_y)/40.0)\n",
    "    length=25\n",
    "    Y_max=np.max(input_y)\n",
    "    plt.hist(input_y,bins=length,density=True)\n",
    "    plt.xlabel('Y value',fontsize=13)\n",
    "    plt.ylabel('Density',fontsize=13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1bc87ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0\n",
      "5 50\n",
      "32.35827041259325 0.7301295149769782 ; 31.979342719519327 0.6449793215786973 ; 32.719935933931204 1.2218591522740005\n",
      "33.221431118183986 0.4816457628107591 ; 33.13960678427112 0.6457423494055771 ; 33.29568233410694 0.7334529776800378\n",
      "10 0\n",
      "10 50\n",
      "32.94118707892555 1.5316070579057302 ; 33.14069579499674 2.6608864637882585 ; 32.6954238329041 0.7473142138863892\n",
      "33.621241181773605 0.4717092315491878 ; 34.05670069550065 0.7041413117474029 ; 33.1733123957007 0.6303997554426797\n",
      "20 0\n",
      "20 50\n",
      "34.43975943570456 1.9234005469853819 ; 35.911089743022174 3.3838368616845615 ; 32.831005798554266 0.8132275967391087\n",
      "33.82633341967093 0.5229009661675429 ; 34.46345400840489 0.6675708101615035 ; 33.17021871916709 0.741480427880604\n",
      "50 0\n",
      "50 50\n",
      "39.2982462304734 1.4421759291638105 ; 44.74386193007782 2.465524532417353 ; 32.922467769503776 0.9397769582828994\n",
      "35.387610914552944 0.5735525761199142 ; 37.395582661302555 0.8839153315767405 ; 33.249769777272796 0.6825235976637521\n",
      "100 0\n",
      "100 50\n",
      "53.10935451853888 2.925951143608134 ; 67.6191091993978 4.5464273447491745 ; 32.63186020955765 0.6908137838623122\n",
      "38.45756567304787 0.9996086876281146 ; 43.148810145105756 1.6553402360702243 ; 33.08994622021195 0.680177152136571\n",
      "200 0\n",
      "200 50\n",
      "92.64929243645663 7.105703616320029 ; 126.88366335490971 10.349866161694441 ; 32.584669796005436 0.6483548999840227\n",
      "48.959873791403524 2.3754037569025597 ; 60.80556925700309 3.7891508386090536 ; 33.065310454124685 0.658708724219354\n",
      "500 0\n",
      "500 50\n",
      "223.1454241559344 19.377708505061936 ; 313.84261061822707 27.53673928583474 ; 32.90724379077161 0.6394319452428973\n",
      "93.5765872357441 8.781395289657992 ; 128.03144781786025 12.757731129695907 ; 33.34889184758251 0.649031946265414\n",
      "1000 0\n",
      "1000 50\n",
      "454.52359659745684 39.11750198293612 ; 641.9731436092347 55.3934321612854 ; 32.33099249919166 0.7177272692033535\n",
      "175.0344106237143 12.331120170101292 ; 245.34784078637068 17.59617147461774 ; 32.74887793454406 0.7249958695636324\n"
     ]
    }
   ],
   "source": [
    "#main program\n",
    "\n",
    "#sample size after sampling\n",
    "N1=1000\n",
    "N2=2000-N1\n",
    "\n",
    "#sample size before sampling\n",
    "N_raw=10000\n",
    "\n",
    "#w for each equation\n",
    "W1=5\n",
    "W2=10\n",
    "W3=500\n",
    "\n",
    "#value range of X\n",
    "X1_max=200\n",
    "X2_max=10\n",
    "X3_max=2*math.pi\n",
    "\n",
    "\n",
    "#consider different sample sizes, different value ranges\n",
    "\n",
    "#Nlist=[1800,1600,1400,1200,1000,800,600,400,200]\n",
    "\n",
    "w1list=[5,10,20,50,100,200,500,1000]\n",
    "# w2list=[10,20,40,100,200,400,1000,2000]\n",
    "# w3list=[500,1000,2000,5000,10000,20000,50000,100000]\n",
    "\n",
    "#for different sample size:\n",
    "# for tt in Nlist:\n",
    "#     N1=tt\n",
    "#     N2=2000-N1\n",
    "#     ...\n",
    "\n",
    "for tt in w1list:\n",
    "    \n",
    "    g_total_rmse=[]\n",
    "    g_rmse_1=[]\n",
    "    g_rmse_2=[]\n",
    "    l_total_rmse=[]\n",
    "    l_rmse_1=[]\n",
    "    l_rmse_2=[]\n",
    "\n",
    "    times=100\n",
    "    \n",
    "\n",
    "    #Linear 0, Power 1, Trigonometric 2\n",
    "    #for different value range, tt\n",
    "    X_rawtrain_1,Y_rawtrain_1=generation(N_raw,tt,X1_max,0)\n",
    "    X_rawtrain_2,Y_rawtrain_2=generation(N_raw,W2,X2_max,1)\n",
    "\n",
    "    X_rawtest_1,Y_rawtest_1=generation(N_raw,tt,X1_max,0)\n",
    "    X_rawtest_2,Y_rawtest_2=generation(N_raw,W2,X2_max,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(times):\n",
    "        #Normal 0, Pareto 1\n",
    "        X_train_1,Y_train_1=densitysampling(N1,X_rawtrain_1,Y_rawtrain_1,0)\n",
    "        X_train_2,Y_train_2=densitysampling(N2,X_rawtrain_2,Y_rawtrain_2,0)\n",
    "        \n",
    "        X_test_1,Y_test_1=densitysampling(N1,X_rawtest_1,Y_rawtest_1,0)\n",
    "        X_test_2,Y_test_2=densitysampling(N2,X_rawtest_2,Y_rawtest_2,0)\n",
    "        \n",
    "        #to avoid the value is to small\n",
    "        Y_train_1=np.log(Y_train_1)*200\n",
    "        Y_train_2=np.log(Y_train_2)*200\n",
    "#         Y_test_1=np.log(Y_test_1)\n",
    "#         Y_test_2=np.log(Y_test_2)\n",
    "        \n",
    "        #tag=0 without log transformation; tag=1 with log transformation\n",
    "        tag=1\n",
    "    \n",
    "        g,g1,g2,l,l1,l2=modeltraining(X_train_1,X_train_2,Y_train_1,Y_train_2,X_test_1,X_test_2,Y_test_1,Y_test_2,tag)\n",
    "    \n",
    "        g_total_rmse.append(g)\n",
    "        g_rmse_1.append(g1)\n",
    "        g_rmse_2.append(g2)\n",
    "        l_total_rmse.append(l)\n",
    "        l_rmse_1.append(l1)\n",
    "        l_rmse_2.append(l2)\n",
    "        \n",
    "        #to show the process\n",
    "        if(i%50==0):\n",
    "            print(tt,i)\n",
    "    #print the results (mean,std) of global training on entire data, data1, and data2; and results of local training on entire data, data1, and data2\n",
    "    print(np.mean(g_total_rmse),np.std(g_total_rmse),';',np.mean(g_rmse_1),np.std(g_rmse_1),';',np.mean(g_rmse_2),np.std(g_rmse_2))\n",
    "    print(np.mean(l_total_rmse),np.std(l_total_rmse),';',np.mean(l_rmse_1),np.std(l_rmse_1),';',np.mean(l_rmse_2),np.std(l_rmse_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0fad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
